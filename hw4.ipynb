{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 10003\n",
      "Test dataset size: 3080\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ random seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "dataset_id = \"banking77\"\n",
    "raw_dataset = load_dataset(dataset_id)\n",
    "\n",
    "print(f\"Train dataset size: {len(raw_dataset['train'])}\")\n",
    "print(f\"Test dataset size: {len(raw_dataset['test'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 2. –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –∏ –º–æ–¥–µ–ª–∏\n",
    "model_name = \"distilbert-base-uncased\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö\n",
    "train_encodings = tokenizer(raw_dataset['train']['text'], truncation=True, padding=True)\n",
    "test_encodings = tokenizer(raw_dataset['test']['text'], truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "class Banking77Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = Banking77Dataset(train_encodings, raw_dataset['train']['label'])\n",
    "test_dataset = Banking77Dataset(test_encodings, raw_dataset['test']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emildenikaev/projects/itmo_dl/itmo_dl/.venv/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='770' max='385' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [385/385 09:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial evaluation: {'eval_loss': 4.347962379455566, 'eval_model_preparation_time': 0.0017, 'eval_accuracy': 0.01396103896103896, 'eval_f1': 0.0017067393290117144, 'eval_runtime': 28.621, 'eval_samples_per_second': 107.613, 'eval_steps_per_second': 13.452}\n"
     ]
    }
   ],
   "source": [
    "# 5. –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏ –¥–æ –¥–æ–æ–±—É—á–µ–Ω–∏—è\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {'accuracy': acc, 'f1': f1}\n",
    "\n",
    "# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,  \n",
    "    per_device_train_batch_size=8, \n",
    "    learning_rate=5e-5,  \n",
    "    evaluation_strategy=\"epoch\", \n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics \n",
    ")\n",
    "\n",
    "# –û—Ü–µ–Ω–∫–∞ –¥–æ –¥–æ–æ–±—É—á–µ–Ω–∏—è\n",
    "initial_eval = trainer.evaluate()\n",
    "print(f\"Initial evaluation: {initial_eval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3753' max='3753' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3753/3753 30:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.525600</td>\n",
       "      <td>0.519816</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.863312</td>\n",
       "      <td>0.858998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.365500</td>\n",
       "      <td>0.313390</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.914610</td>\n",
       "      <td>0.914385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>0.293648</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.923052</td>\n",
       "      <td>0.923020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3753, training_loss=0.7072711554950248, metrics={'train_runtime': 1845.2877, 'train_samples_per_second': 16.263, 'train_steps_per_second': 2.034, 'total_flos': 761898528728316.0, 'train_loss': 0.7072711554950248, 'epoch': 3.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏ –¥–æ –∏ –ø–æ—Å–ª–µ –¥–æ–æ–±—É—á–µ–Ω–∏—è\n",
    "def evaluate_model(dataset, device):\n",
    "    model.eval()\n",
    "    pred_labels = []\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # –°–æ–∑–¥–∞–Ω–∏–µ DataLoader –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –Ω–∞–±–æ—Ä–∞\n",
    "    test_loader = torch.utils.data.DataLoader(dataset, batch_size=16)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            # –ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –∑–∞–¥–∞–Ω–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ\n",
    "            for key in batch:\n",
    "                batch[key] = batch[key].to(device)\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "            pred_labels.extend(logits.argmax(dim=-1).tolist())\n",
    "\n",
    "    return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final evaluation: {'eval_loss': 0.29364821314811707, 'eval_model_preparation_time': 0.0017, 'eval_accuracy': 0.923051948051948, 'eval_f1': 0.9230196335238754, 'eval_runtime': 30.2876, 'eval_samples_per_second': 101.692, 'eval_steps_per_second': 12.711, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏ –ø–æ—Å–ª–µ –¥–æ–æ–±—É—á–µ–Ω–∏—è\n",
    "final_eval = trainer.evaluate()\n",
    "print(f\"Final evaluation: {final_eval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Accuracy: 0.01396103896103896, Initial F1 Score: 0.0017067393290117144\n",
      "Final Accuracy: 0.923051948051948, Final F1 Score: 0.9230196335238754\n"
     ]
    }
   ],
   "source": [
    "print(f\"Initial Accuracy: {initial_eval['eval_accuracy']}, Initial F1 Score: {initial_eval['eval_f1']}\")\n",
    "print(f\"Final Accuracy: {final_eval['eval_accuracy']}, Final F1 Score: {final_eval['eval_f1']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å–ª–µ –Ω–∞—á–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤, –≥–¥–µ —Ç–æ—á–Ω–æ—Å—Ç—å —Å–æ—Å—Ç–∞–≤–∏–ª–∞ –≤—Å–µ–≥–æ 1.40% –∏ F1-–º–µ—Ç—Ä–∏–∫–∞ 0.17%, –º–æ–¥–µ–ª—å –±—ã–ª–∞ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–ª—É—á—à–µ–Ω–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –¥–æ–æ–±—É—á–µ–Ω–∏—è, —á—Ç–æ –ø—Ä–∏–≤–µ–ª–æ –∫ –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ 92.31% –∏ F1-–º–µ—Ç—Ä–∏–∫–µ 92.30%. –≠—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–≤–∏–¥–µ—Ç–µ–ª—å—Å—Ç–≤—É—é—Ç –æ –≤—ã—Å–æ–∫–æ–º –∫–∞—á–µ—Å—Ç–≤–µ –º–æ–¥–µ–ª–∏ –ø–æ—Å–ª–µ –¥–æ–æ–±—É—á–µ–Ω–∏—è, –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—è –µ–µ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ —Ä–µ—à–∞—Ç—å –∑–∞–¥–∞—á—É –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–∞ –≤—ã–±—Ä–∞–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
