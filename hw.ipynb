{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   svcscan.fs_drivers  callbacks.ngeneric  \\\n",
      "0                  26                   8   \n",
      "1                  26                   8   \n",
      "2                  26                   8   \n",
      "3                  26                   8   \n",
      "4                  26                   8   \n",
      "\n",
      "   psxview.not_in_eprocess_pool_false_avg  psxview.not_in_eprocess_pool  \\\n",
      "0                                     0.0                             0   \n",
      "1                                     0.0                             0   \n",
      "2                                     0.0                             0   \n",
      "3                                     0.0                             0   \n",
      "4                                     0.0                             0   \n",
      "\n",
      "   callbacks.nanonymous  psxview.not_in_session  psxview.not_in_pslist  \\\n",
      "0                     0                       2                      0   \n",
      "1                     0                       5                      3   \n",
      "2                     0                       9                      7   \n",
      "3                     0                       3                      1   \n",
      "4                     0                       2                      0   \n",
      "\n",
      "   psxview.not_in_pspcid_list  psxview.not_in_ethread_pool  \\\n",
      "0                           0                            0   \n",
      "1                           3                            3   \n",
      "2                           7                            7   \n",
      "3                           1                            2   \n",
      "4                           0                            0   \n",
      "\n",
      "   psxview.not_in_csrss_handles  psxview.not_in_pslist_false_avg  \\\n",
      "0                             4                         0.000000   \n",
      "1                             7                         0.073171   \n",
      "2                            11                         0.152174   \n",
      "3                             6                         0.022222   \n",
      "4                             4                         0.000000   \n",
      "\n",
      "   psxview.not_in_pspcid_list_false_avg  psxview.not_in_deskthrd  \\\n",
      "0                              0.000000                        6   \n",
      "1                              0.073171                        9   \n",
      "2                              0.152174                       13   \n",
      "3                              0.022222                        9   \n",
      "4                              0.000000                        6   \n",
      "\n",
      "   psxview.not_in_ethread_pool_false_avg  psxview.not_in_session_false_avg  \\\n",
      "0                               0.000000                          0.044444   \n",
      "1                               0.073171                          0.121951   \n",
      "2                               0.152174                          0.195652   \n",
      "3                               0.044444                          0.066667   \n",
      "4                               0.000000                          0.048780   \n",
      "\n",
      "   Class  \n",
      "0      1  \n",
      "1      1  \n",
      "2      1  \n",
      "3      1  \n",
      "4      0  \n"
     ]
    }
   ],
   "source": [
    "# 1. Загрузка данных\n",
    "df = pd.read_csv('./content/cybersequrity.csv')\n",
    "\n",
    "# Просмотр первых 5 строк\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Определение признаков и целевой переменной\n",
    "X = df.drop(columns='Class').values  # Все столбцы, кроме 'Class'\n",
    "y = df['Class'].values  # Целевая переменная\n",
    "\n",
    "# Разделение на обучающую, валидационную и тестовую выборки (60/20/20) со стратификацией\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, stratify=y, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Стандартизация данных\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Преобразование данных в тензоры\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "X_val_tensor = torch.FloatTensor(X_val)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_train_tensor = torch.FloatTensor(y_train)\n",
    "y_val_tensor = torch.FloatTensor(y_val)\n",
    "y_test_tensor = torch.FloatTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Создание класса Dataset\n",
    "class CybersecurityDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Выбор batch_size\n",
    "batch_size = 32  # Можно попробовать другие значения, если качество модели не устраивает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Создание DataLoader\n",
    "train_dataset = CybersecurityDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = CybersecurityDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = CybersecurityDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 188, Validation size: 63, Test size: 63\n"
     ]
    }
   ],
   "source": [
    "# 8. Проверка размерностей выборок\n",
    "print(f'Train size: {len(train_loader)}, Validation size: {len(val_loader)}, Test size: {len(test_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализация класса MLP\n",
    "\n",
    "1. Структура модели: Мы используем несколько линейных слоев для обработки данных.\n",
    "2. Функции активации: Часто используемыми функциями активации в скрытых слоях являются ReLU и LeakyReLU.\n",
    "3. Метод forward: Реализуем логику прохождения данных через сеть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=15, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=32, out_features=1, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # Определяем слои\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "        \n",
    "        # Создаем скрытые слои\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(in_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())  # Используем активацию ReLU\n",
    "            in_dim = hidden_dim\n",
    "        \n",
    "        # Выходной слой\n",
    "        layers.append(nn.Linear(in_dim, output_dim))\n",
    "        layers.append(nn.Sigmoid())  # Используем сигмоид для бинарной классификации\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Параметры модели\n",
    "input_dim = X_train.shape[1]  # Количество входных признаков\n",
    "hidden_dims = [64, 32]  # Размерности скрытых слоев\n",
    "output_dim = 1  # Для бинарной классификации\n",
    "\n",
    "# Создание объекта модели\n",
    "model = MLP(input_dim, hidden_dims, output_dim)\n",
    "\n",
    "# Проверка наличия GPU и перевод модели на GPU, если доступен\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Печать структуры модели\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение и валидации модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение функции потерь и оптимизатора\n",
    "criterion = nn.BCELoss()  # Функция потерь для бинарной классификации\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Оптимизатор Adam\n",
    "\n",
    "# Параметры обучения\n",
    "num_epochs = 50\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()  # Устанавливаем режим обучения\n",
    "    running_loss = 0.0\n",
    "    for features, labels in train_loader:\n",
    "        features, labels = features.to(device), labels.to(device)  # Перенос данных на устройство\n",
    "        optimizer.zero_grad()  # Обнуляем градиенты\n",
    "        outputs = model(features).squeeze()  # Прямой проход\n",
    "        loss = criterion(outputs, labels)  # Вычисляем функцию потерь\n",
    "        loss.backward()  # Обратное распространение ошибки\n",
    "        optimizer.step()  # Обновляем параметры\n",
    "        running_loss += loss.item()  # Сохраняем потери\n",
    "\n",
    "    return running_loss / len(train_loader)  # Возвращаем среднюю потерю\n",
    "\n",
    "def evaluate(model, val_loader, criterion):\n",
    "    model.eval()  # Устанавливаем режим валидации\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():  # Выключаем градиенты\n",
    "        for features, labels in val_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = model(features).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(val_loader)  # Возвращаем среднюю потерю\n",
    "\n",
    "# Цикл обучения и валидации\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_loader, criterion, optimizer)\n",
    "    val_loss = evaluate(model, val_loader, criterion)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "# Визуализация потерь\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss', color='blue')\n",
    "plt.plot(range(1, num_epochs + 1), val_losses, label='Val Loss', color='orange')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестирование модели\n",
    "model.eval()\n",
    "y_pred_list = []\n",
    "y_true_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "        features = features.to(device)\n",
    "        outputs = model(features).squeeze()\n",
    "        predicted = (outputs > 0.5).float()  # Преобразуем вероятности в класс\n",
    "        y_pred_list.extend(predicted.cpu().numpy())\n",
    "        y_true_list.extend(labels.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отчет о классификации\n",
    "\n",
    "print(classification_report(y_true_list, y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализация улучшенной модели\n",
    "\n",
    "class ImprovedMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim, dropout_rate):\n",
    "        super(ImprovedMLP, self).__init__()\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(in_dim, hidden_dim))\n",
    "            layers.append(nn.BatchNorm1d(hidden_dim))  # Добавляем слой нормализации\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))  # Добавляем слой Dropout\n",
    "            in_dim = hidden_dim\n",
    "\n",
    "        layers.append(nn.Linear(in_dim, output_dim))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Определение гиперпараметров\n",
    "dropout_rate = 0.3 \n",
    "hidden_dims = [64, 32]  # Размерности скрытых слоев\n",
    "\n",
    "# Создание и перенос улучшенной модели на устройство\n",
    "improved_model = ImprovedMLP(input_dim, hidden_dims, output_dim, dropout_rate)\n",
    "improved_model.to(device)\n",
    "\n",
    "# Параметры обучения\n",
    "num_epochs = 50\n",
    "optimizer = optim.Adam(improved_model.parameters(), lr=0.001) \n",
    "\n",
    "# Обучение улучшенной модели\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(improved_model, train_loader, criterion, optimizer)\n",
    "    val_loss = evaluate(improved_model, val_loader, criterion)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "# Визуализация потерь\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss', color='blue')\n",
    "plt.plot(range(1, num_epochs + 1), val_losses, label='Val Loss', color='orange')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train and Validation Loss (Improved Model)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестирование улучшенной модели\n",
    "improved_model.eval()\n",
    "y_pred_list = []\n",
    "y_true_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "        features = features.to(device)\n",
    "        outputs = improved_model(features).squeeze()\n",
    "        predicted = (outputs > 0.5).float()  # Преобразуем вероятности в класс\n",
    "        y_pred_list.extend(predicted.cpu().numpy())\n",
    "        y_true_list.extend(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отчет о классификации\n",
    "print(\"Classification Report for Improved Model:\")\n",
    "print(classification_report(y_true_list, y_pred_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
